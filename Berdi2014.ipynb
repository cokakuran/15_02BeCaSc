{
 "metadata": {
  "name": "",
  "signature": "sha256:80783c26c86973a7bc9fbfd07b9b50cfd3228c7d57ee75cda82f6031f4266f1e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Importing Alex data using panda"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We first import os, numpy, and pandas to deal with the data. We also import re to find the name of the mice."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import re\n",
      "from datetime import datetime as dt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we load the data in all the datasets in "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def date_parser_f(date):\n",
      "    return dt.strptime(date, \"%Y-%m-%d %H:%M:%S.%f\")\n",
      "\n",
      "path = \"/home/rcaze/Data/Berdi2014/\"\n",
      "re_name = r'[A-Za-z0-9]*'\n",
      "datasets = []\n",
      "for fname in os.listdir(path):\n",
      "    c_names = [\"Date\", \"Lick\", \"Period\", \"Trial\", \"Stim\", \"Outcome\"]\n",
      "    datasets.append(pd.read_csv(path + fname, parse_dates=\"Timestamp\", date_parser=date_parser_f))\n",
      "    datasets[-1].columns = c_names\n",
      "    del datasets[-1][\"Outcome\"]\n",
      "    mice_name = re.match(re_name, fname)\n",
      "    datasets[-1]['MouseName'] = mice_name.group()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datasets[0]['Date'][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 89,
       "text": [
        "'2013-11-05 11:04:57.771'"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Date column is the index and we look at the first few rows of one dataset."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = datasets[1]\n",
      "test.index = test['Date']\n",
      "test.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "                                            Date  Lick Period  Trial  Stim MouseName\n",
        "2013-11-05 13:06:33.874  2013-11-05 13:06:33.874     0    ITI      1     1     raisa\n",
        "2013-11-05 13:06:33.894  2013-11-05 13:06:33.894     0    ITI      1     1     raisa\n",
        "2013-11-05 13:06:33.914  2013-11-05 13:06:33.914     1    ITI      1     1     raisa\n",
        "2013-11-05 13:06:33.934  2013-11-05 13:06:33.934     1    ITI      1     1     raisa\n",
        "2013-11-05 13:06:33.954  2013-11-05 13:06:33.954     0    ITI      1     1     raisa"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are grouping the data and remove the superfluous date column"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_data = pd.concat(datasets)\n",
      "all_data.index = all_data['Date']\n",
      "del all_data['Date']\n",
      "all_data.to_csv('test.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Plotting Alex's data and obtaining a lick report"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from datetime import datetime as dt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "date = all_data.index[0]\n",
      "print date\n",
      "def date_parser_f(date):\n",
      "    return dt.strptime(date, \"%Y-%m-%d %H:%M:%S.%f\")\n",
      "date_parser_f(date)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2013-11-05 11:04:57.771\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "datetime.datetime(2013, 11, 5, 11, 4, 57, 771000)"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a.microsecond"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "771000"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first plot to obtain would be the lick report from the session. For that we need to use raster and to extract the data into a nice way."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "A deterministic task learned by reinforcement learning"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first task is to have a model of task as close as possible from Alexandra's task. In informal term, the task consists to lick when a vertical stimulus is presented to the mouse and to withhold licking when an horizontal stimulus is presented. The two sets of stimulus are presented in a pseudo-random sequence.\n",
      "\n",
      "On can use an elementary model to describe the behaviour of the mouse. An agent with four Q-values, two actions in for each of the two states: $[Q_{0,0},Q_{0,1},Q_{1,0},Q_{1,1}]$. A $Q$-value is updated using a simple delta rule, where $Q(t)$ and $r(t)$ are $Q$-value and reward for the trial t and $\\alpha$ is the learning rate of the agent: $Q(t+1) = Q(t) + \\alpha (r(t)-Q(t))$. In each trial only one $Q$ is updated depending on the state and the action."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run lib.py\n",
      "states = stimulus(100, 0.5)\n",
      "rec_q, rec_action, rec_reward = testbed(states)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print rec_action\n",
      "print states"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1\n",
        " 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1]\n",
        "[0 1 0 1 0 1 0 1 0 0 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1\n",
        " 0 0 1 1 0 0 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 1 0]\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This little piece of script is showing that an agent learns really fast this easy task. Reward at deterministic and in both state the number of actions is two, so theoretically a one shot learning is sufficient. In order to match the behavioral observation one need to degrad the behavior. But first I will work on an ROC representation of the result and try to obtain the same kind of ROC plot as Alex.\n",
      "\n",
      "I need to design a function with a sliding window, to determine the hit and false alarm rate, given a set of states and a set of actions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run lib.py\n",
      "states = stimulus(100, 0.5)\n",
      "rec_q, rec_actions, rec_reward = testbed(states)\n",
      "spe_traj, sen_traj = sliding_estimate(states, rec_actions, 20)\n",
      "ROC(spe_traj, sen_traj)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "need more than 2 values to unpack",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-4-8a3c546ef27c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstimulus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mrec_q\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrec_actions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrec_reward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestbed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mspe_traj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msen_traj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msliding_estimate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrec_actions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mROC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspe_traj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msen_traj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/rcaze/Content/Scripts/PYTHON/Berdi2014/lib.py\u001b[0m in \u001b[0;36msliding_estimate\u001b[1;34m(target, actual, window_s)\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_windows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m         spe, sen, matt = spe_sen(target[i:i + window_s],\n\u001b[1;32m--> 272\u001b[1;33m                                  actual[i:i + window_s])\n\u001b[0m\u001b[0;32m    273\u001b[0m         \u001b[0mspe_traj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspe\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[0msen_traj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msen\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: need more than 2 values to unpack"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rec_q"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "array([[[-3.  ,  3.  ],\n",
        "        [-3.  ,  3.  ]],\n",
        "\n",
        "       [[-2.97,  2.97],\n",
        "        [-2.97,  2.97]],\n",
        "\n",
        "       [[-2.94,  2.94],\n",
        "        [-2.94,  2.94]],\n",
        "\n",
        "       [[-2.91,  2.91],\n",
        "        [-2.91,  2.91]],\n",
        "\n",
        "       [[-2.88,  2.88],\n",
        "        [-2.88,  2.88]],\n",
        "\n",
        "       [[-2.85,  2.85],\n",
        "        [-2.85,  2.85]],\n",
        "\n",
        "       [[-2.82,  2.82],\n",
        "        [-2.82,  2.82]],\n",
        "\n",
        "       [[-2.79,  2.79],\n",
        "        [-2.79,  2.79]],\n",
        "\n",
        "       [[-2.76,  2.76],\n",
        "        [-2.76,  2.76]],\n",
        "\n",
        "       [[-2.73,  2.73],\n",
        "        [-2.73,  2.73]],\n",
        "\n",
        "       [[-2.7 ,  2.7 ],\n",
        "        [-2.7 ,  2.7 ]],\n",
        "\n",
        "       [[-2.67,  2.67],\n",
        "        [-2.67,  2.67]],\n",
        "\n",
        "       [[-2.64,  2.64],\n",
        "        [-2.64,  2.64]],\n",
        "\n",
        "       [[-2.61,  2.61],\n",
        "        [-2.61,  2.61]],\n",
        "\n",
        "       [[-2.58,  2.58],\n",
        "        [-2.58,  2.58]],\n",
        "\n",
        "       [[-2.55,  2.55],\n",
        "        [-2.55,  2.55]],\n",
        "\n",
        "       [[-2.52,  2.52],\n",
        "        [-2.52,  2.52]],\n",
        "\n",
        "       [[-2.49,  2.49],\n",
        "        [-2.49,  2.49]],\n",
        "\n",
        "       [[-2.46,  2.46],\n",
        "        [-2.46,  2.46]],\n",
        "\n",
        "       [[-2.43,  2.43],\n",
        "        [-2.43,  2.43]],\n",
        "\n",
        "       [[-2.4 ,  2.4 ],\n",
        "        [-2.4 ,  2.4 ]],\n",
        "\n",
        "       [[-2.37,  2.37],\n",
        "        [-2.37,  2.37]],\n",
        "\n",
        "       [[-2.34,  2.34],\n",
        "        [-2.34,  2.34]],\n",
        "\n",
        "       [[-2.31,  2.31],\n",
        "        [-2.31,  2.31]],\n",
        "\n",
        "       [[-2.28,  2.28],\n",
        "        [-2.28,  2.28]],\n",
        "\n",
        "       [[-2.25,  2.25],\n",
        "        [-2.25,  2.25]],\n",
        "\n",
        "       [[-2.22,  2.22],\n",
        "        [-2.22,  2.22]],\n",
        "\n",
        "       [[-2.19,  2.19],\n",
        "        [-2.19,  2.19]],\n",
        "\n",
        "       [[-2.16,  2.16],\n",
        "        [-2.16,  2.16]],\n",
        "\n",
        "       [[-2.13,  2.13],\n",
        "        [-2.13,  2.13]],\n",
        "\n",
        "       [[-2.1 ,  2.1 ],\n",
        "        [-2.1 ,  2.1 ]],\n",
        "\n",
        "       [[-2.07,  2.07],\n",
        "        [-2.07,  2.07]],\n",
        "\n",
        "       [[-2.04,  2.04],\n",
        "        [-2.04,  2.04]],\n",
        "\n",
        "       [[-2.01,  2.01],\n",
        "        [-2.01,  2.01]],\n",
        "\n",
        "       [[-1.98,  1.98],\n",
        "        [-1.98,  1.98]],\n",
        "\n",
        "       [[-1.95,  1.95],\n",
        "        [-1.95,  1.95]],\n",
        "\n",
        "       [[-1.92,  1.92],\n",
        "        [-1.92,  1.92]],\n",
        "\n",
        "       [[-1.89,  1.89],\n",
        "        [-1.89,  1.89]],\n",
        "\n",
        "       [[-1.86,  1.86],\n",
        "        [-1.86,  1.86]],\n",
        "\n",
        "       [[-1.83,  1.83],\n",
        "        [-1.83,  1.83]],\n",
        "\n",
        "       [[-1.8 ,  1.8 ],\n",
        "        [-1.8 ,  1.8 ]],\n",
        "\n",
        "       [[-1.77,  1.77],\n",
        "        [-1.77,  1.77]],\n",
        "\n",
        "       [[-1.74,  1.74],\n",
        "        [-1.74,  1.74]],\n",
        "\n",
        "       [[-1.71,  1.71],\n",
        "        [-1.71,  1.71]],\n",
        "\n",
        "       [[-1.68,  1.68],\n",
        "        [-1.68,  1.68]],\n",
        "\n",
        "       [[-1.65,  1.65],\n",
        "        [-1.65,  1.65]],\n",
        "\n",
        "       [[-1.62,  1.62],\n",
        "        [-1.62,  1.62]],\n",
        "\n",
        "       [[-1.59,  1.59],\n",
        "        [-1.59,  1.59]],\n",
        "\n",
        "       [[-1.56,  1.56],\n",
        "        [-1.56,  1.56]],\n",
        "\n",
        "       [[-1.53,  1.53],\n",
        "        [-1.53,  1.53]],\n",
        "\n",
        "       [[-1.5 ,  1.5 ],\n",
        "        [-1.5 ,  1.5 ]],\n",
        "\n",
        "       [[-1.47,  1.47],\n",
        "        [-1.47,  1.47]],\n",
        "\n",
        "       [[-1.44,  1.44],\n",
        "        [-1.44,  1.44]],\n",
        "\n",
        "       [[-1.41,  1.41],\n",
        "        [-1.41,  1.41]],\n",
        "\n",
        "       [[-1.38,  1.38],\n",
        "        [-1.38,  1.38]],\n",
        "\n",
        "       [[-1.35,  1.35],\n",
        "        [-1.35,  1.35]],\n",
        "\n",
        "       [[-1.32,  1.32],\n",
        "        [-1.32,  1.32]],\n",
        "\n",
        "       [[-1.29,  1.29],\n",
        "        [-1.29,  1.29]],\n",
        "\n",
        "       [[-1.26,  1.26],\n",
        "        [-1.26,  1.26]],\n",
        "\n",
        "       [[-1.23,  1.23],\n",
        "        [-1.23,  1.23]],\n",
        "\n",
        "       [[-1.2 ,  1.2 ],\n",
        "        [-1.2 ,  1.2 ]],\n",
        "\n",
        "       [[-1.17,  1.17],\n",
        "        [-1.17,  1.17]],\n",
        "\n",
        "       [[-1.14,  1.14],\n",
        "        [-1.14,  1.14]],\n",
        "\n",
        "       [[-1.11,  1.11],\n",
        "        [-1.11,  1.11]],\n",
        "\n",
        "       [[-1.08,  1.08],\n",
        "        [-1.08,  1.08]],\n",
        "\n",
        "       [[-1.05,  1.05],\n",
        "        [-1.05,  1.05]],\n",
        "\n",
        "       [[-1.02,  1.02],\n",
        "        [-1.02,  1.02]],\n",
        "\n",
        "       [[-0.99,  0.99],\n",
        "        [-0.99,  0.99]],\n",
        "\n",
        "       [[-0.96,  0.96],\n",
        "        [-0.96,  0.96]],\n",
        "\n",
        "       [[-0.93,  0.93],\n",
        "        [-0.93,  0.93]],\n",
        "\n",
        "       [[-0.9 ,  0.9 ],\n",
        "        [-0.9 ,  0.9 ]],\n",
        "\n",
        "       [[-0.87,  0.87],\n",
        "        [-0.87,  0.87]],\n",
        "\n",
        "       [[-0.84,  0.84],\n",
        "        [-0.84,  0.84]],\n",
        "\n",
        "       [[-0.81,  0.81],\n",
        "        [-0.81,  0.81]],\n",
        "\n",
        "       [[-0.78,  0.78],\n",
        "        [-0.78,  0.78]],\n",
        "\n",
        "       [[-0.75,  0.75],\n",
        "        [-0.75,  0.75]],\n",
        "\n",
        "       [[-0.72,  0.72],\n",
        "        [-0.72,  0.72]],\n",
        "\n",
        "       [[-0.69,  0.69],\n",
        "        [-0.69,  0.69]],\n",
        "\n",
        "       [[-0.66,  0.66],\n",
        "        [-0.66,  0.66]],\n",
        "\n",
        "       [[-0.63,  0.63],\n",
        "        [-0.63,  0.63]],\n",
        "\n",
        "       [[-0.6 ,  0.6 ],\n",
        "        [-0.6 ,  0.6 ]],\n",
        "\n",
        "       [[-0.57,  0.57],\n",
        "        [-0.57,  0.57]],\n",
        "\n",
        "       [[-0.54,  0.54],\n",
        "        [-0.54,  0.54]],\n",
        "\n",
        "       [[-0.51,  0.51],\n",
        "        [-0.51,  0.51]],\n",
        "\n",
        "       [[-0.48,  0.48],\n",
        "        [-0.48,  0.48]],\n",
        "\n",
        "       [[-0.45,  0.45],\n",
        "        [-0.45,  0.45]],\n",
        "\n",
        "       [[-0.42,  0.42],\n",
        "        [-0.42,  0.42]],\n",
        "\n",
        "       [[-0.39,  0.39],\n",
        "        [-0.39,  0.39]],\n",
        "\n",
        "       [[-0.36,  0.36],\n",
        "        [-0.36,  0.36]],\n",
        "\n",
        "       [[-0.33,  0.33],\n",
        "        [-0.33,  0.33]],\n",
        "\n",
        "       [[-0.3 ,  0.3 ],\n",
        "        [-0.3 ,  0.3 ]],\n",
        "\n",
        "       [[-0.27,  0.27],\n",
        "        [-0.27,  0.27]],\n",
        "\n",
        "       [[-0.24,  0.24],\n",
        "        [-0.24,  0.24]],\n",
        "\n",
        "       [[-0.21,  0.21],\n",
        "        [-0.21,  0.21]],\n",
        "\n",
        "       [[-0.18,  0.18],\n",
        "        [-0.18,  0.18]],\n",
        "\n",
        "       [[-0.15,  0.15],\n",
        "        [-0.15,  0.15]],\n",
        "\n",
        "       [[-0.12,  0.12],\n",
        "        [-0.12,  0.12]],\n",
        "\n",
        "       [[-0.09,  0.09],\n",
        "        [-0.09,  0.09]],\n",
        "\n",
        "       [[-0.06,  0.06],\n",
        "        [-0.06,  0.06]],\n",
        "\n",
        "       [[-0.03,  0.03],\n",
        "        [-0.03,  0.03]]])"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The type of ROC observed by Alex look like this one. The problem illustrated by the code snippet below is that there is a lot of variation in the possible outcome due to the high temperature necessary to reproduce the experimental results."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run lib.py\n",
      "states = stimulus(100, 0.5)\n",
      "rec_q, rec_actions, rec_reward = testbed(states)\n",
      "spe_traj, sen_traj = sliding_estimate(states, rec_actions, 20)\n",
      "ROC(spe_traj, sen_traj)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "need more than 2 values to unpack",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-6-8a3c546ef27c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstimulus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mrec_q\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrec_actions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrec_reward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestbed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mspe_traj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msen_traj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msliding_estimate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrec_actions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mROC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspe_traj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msen_traj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/rcaze/Content/Scripts/PYTHON/Berdi2014/lib.py\u001b[0m in \u001b[0;36msliding_estimate\u001b[1;34m(target, actual, window_s)\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_windows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m         spe, sen, matt = spe_sen(target[i:i + window_s],\n\u001b[1;32m--> 272\u001b[1;33m                                  actual[i:i + window_s])\n\u001b[0m\u001b[0;32m    273\u001b[0m         \u001b[0mspe_traj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspe\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[0msen_traj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msen\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: need more than 2 values to unpack"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I saw one of Alex's mice training session. There are many interesting things I learned from it. First there is a lot of information in the licking frequency. The mice are licking a lot in the interstimulus intervals, especially at the beginning of the session. This could give us information about the motivational level of a mouse. Another interesting fact is that mice tend to stop licking when the loud sounds starts, it might mean that mice are using that as a clue to stop licking an not as a punishment. One way to make sure that it is not the case is to take into account only licks that happen before the sound onset, so to see the licking frequency from the onset of the stimulus. I have also new questions. How is the punishment triggered? It seems that the mouse need to lick more than once. Using just auditory cues might also be an idea."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Explaining the change in motivation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I define three variables $G$, $G_{p}$, and $L$. $G$ is the image projected on the screen $G=0$ means no-go image and $G=1$ means go image, this variable is deterministic and varies given the experimentalist wish. $G_{p}$ is the perceived image by the subject $G_{p}=0$ means it is the no-go percept and $G_{p}=1$ means the go percept. The subject never licks if it perceive a no-go, however, it licks with a probability $p(m)$ with $m$ a variable depending on the motivational state of the subject.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "duration = 300\n",
      "#Perceptual noise should be between 0 and 0.5 (max).\n",
      "perceptual_noise = 0.3\n",
      "\n",
      "#Generate a G vector\n",
      "G = np.array([0 if i%2 == 0 else 1 for i in range(duration)])\n",
      "print \"Vector of G\" \n",
      "print G\n",
      "print \"\\n\"\n",
      "\n",
      "#Generate the G perceived vector\n",
      "R = np.random.random(duration) > perceptual_noise\n",
      "Gp = np.array(np.bitwise_xor(G,R) < 1, np.int) \n",
      "print \"Vector of perceived G\" \n",
      "print Gp\n",
      "print \"\\n\"\n",
      "\n",
      "#Generate the L vector\n",
      "R2 = np.random.random(duration)\n",
      "#Initialize vectors to record licks and motivation\n",
      "L = np.zeros(duration, np.int)\n",
      "motiv = np.ones(duration, np.float)\n",
      "#initial motivation\n",
      "m = 1\n",
      "for i in range(duration):\n",
      "    if Gp[i] == 1 and R2[i] < m:\n",
      "        L[i] = 1\n",
      "        if G[i] == 1:\n",
      "            m -= 0.01\n",
      "    else:\n",
      "        L[i] = 0\n",
      "\n",
      "print \"Vector of L\"\n",
      "print L"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Vector of G\n",
        "[0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
        " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
        " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
        " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
        " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
        " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
        " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
        " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
        " 0 1 0 1]\n",
        "\n",
        "\n",
        "Vector of perceived G\n",
        "[0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0\n",
        " 1 0 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 1 1 0 1\n",
        " 0 1 1 1 0 1 0 0 1 1 0 1 0 1 0 1 1 1 0 1 0 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 0\n",
        " 0 1 1 0 1 0 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1\n",
        " 1 1 0 1 0 1 0 1 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 1 0 1 1 1 0 0 0 1 0\n",
        " 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 1 1 0 0 1 0 1\n",
        " 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 0 1 1 1 0\n",
        " 1 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 1 1 0 1\n",
        " 1 1 0 1]\n",
        "\n",
        "\n",
        "Vector of L\n",
        "[0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0\n",
        " 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 1 1 0 1\n",
        " 0 1 1 1 0 1 0 0 1 1 0 1 0 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 0 1 1 0 1 1 0 1 0\n",
        " 0 1 1 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 1 1 0 1 0 1 0 1 0 0\n",
        " 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0\n",
        " 1 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
        " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0\n",
        " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0\n",
        " 0 0 0 1]\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we have these three variables we can factorized the code to iterate the experiment and compute the mean specificity and sensitivity along time."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def spe_sen(target, actual):\n",
      "    \"\"\"Compute the (specificity,sensitivity) couple and the Matthews correlation coefficient\n",
      "    for a desired Boolean function called ftar for a neuron implementing the Boolean function f.\n",
      "\n",
      "    parameters\n",
      "    ----------\n",
      "    target : Boolean array\n",
      "        actions taken\n",
      "    actual : Boolean array\n",
      "        actions expected\n",
      "\n",
      "    returns\n",
      "    -------\n",
      "    spe : a float between 0 and 1\n",
      "    sen : a float between 0 and 1\n",
      "    \"\"\"\n",
      "    #Use the binary of the vector to see the difference between actual and target\n",
      "    tp = np.array(target)*2 - actual\n",
      "    TN = len(np.repeat(tp,tp==0))\n",
      "    FN = len(np.repeat(tp,tp==2))\n",
      "    TP = len(np.repeat(tp,tp==1))\n",
      "    FP = len(np.repeat(tp,tp==-1))\n",
      "\n",
      "    spe = float(TN)/(TN+FP)\n",
      "    sen = float(TP)/(TP+FN)\n",
      "\n",
      "    return spe, sen\n",
      "def spe_sen(target, actual):\n",
      "    \"\"\"Compute the (specificity,sensitivity) couple and the Matthews correlation coefficient\n",
      "    for a desired Boolean function called ftar for a neuron implementing the Boolean function f.\n",
      "\n",
      "    parameters\n",
      "    ----------\n",
      "    target : Boolean array\n",
      "        actions taken\n",
      "    actual : Boolean array\n",
      "        actions expected\n",
      "\n",
      "    returns\n",
      "    -------\n",
      "    spe : a float between 0 and 1\n",
      "    sen : a float between 0 and 1\n",
      "    \"\"\"\n",
      "    #Use the binary of the vector to see the difference between actual and target\n",
      "    tp = np.array(target)*2 - actual\n",
      "    TN = len(np.repeat(tp,tp==0))\n",
      "    FN = len(np.repeat(tp,tp==2))\n",
      "    TP = len(np.repeat(tp,tp==1))\n",
      "    FP = len(np.repeat(tp,tp==-1))\n",
      "\n",
      "    spe = float(TN)/(TN+FP)\n",
      "    sen = float(TP)/(TP+FN)\n",
      "\n",
      "    return spe, sen\n",
      "\n",
      "def expe(perceptual_noise = 0.3, duration = 300):\n",
      "    #Generate a G vector\n",
      "    G = np.array([0 if i%2 == 0 else 1 for i in range(duration)])\n",
      "\n",
      "    #Generate the G perceived vector\n",
      "    R = np.random.random(duration) > perceptual_noise\n",
      "    Gp = np.array(np.bitwise_xor(G,R) < 1, np.int) \n",
      "\n",
      "    #Generate the L vector\n",
      "    R2 = np.random.random(duration)\n",
      "    #Initialize vectors to record licks and motivation\n",
      "    L = np.zeros(duration, np.int)\n",
      "    motiv = np.ones(duration, np.float)\n",
      "    #initial motivation\n",
      "    m = 1\n",
      "    for i in range(duration):\n",
      "        if Gp[i] == 1 and R2[i] < m:\n",
      "            L[i] = 1\n",
      "            if G[i] == 1:\n",
      "                m -= 0.01\n",
      "        else:\n",
      "            L[i] = 0\n",
      "\n",
      "    return G, Gp, L\n",
      "\n",
      "def analysis(L, G, n_chunks=10):\n",
      "    #Split the vectors into n_chunks\n",
      "    G_split = np.array_split(G, n_chunks)\n",
      "    L_split = np.array_split(L, n_chunks)\n",
      "    spe = np.zeros(n_chunks)\n",
      "    sen = np.zeros(n_chunks)\n",
      "    \n",
      "    for i in range(n_chunks):\n",
      "        spe[i], sen[i] = spe_sen(G_split[i], L_split[i])\n",
      "    return spe, sen\n",
      "\n",
      "p_n = 0.4\n",
      "dur = 300\n",
      "repetition = 1000\n",
      "n_c = 10\n",
      "spe = np.zeros((repetition, n_c))\n",
      "sen = np.zeros((repetition, n_c))\n",
      "for i in range(repetition):\n",
      "    G, Gp, L = expe(p_n, dur)\n",
      "    spe[i], sen[i] = analysis(L, G, n_c)\n",
      "\n",
      "plot(1 - np.mean(spe, axis=0), color='r')\n",
      "plot(np.mean(sen, axis=0), color='g')\n",
      "plt.xlabel(\"Chunk#\")\n",
      "plt.ylabel(\"Probability\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "<matplotlib.text.Text at 0x2e62f10>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEKCAYAAAD0Luk/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCGHCpASEEMKESQkIIYQJkxIQQggT9v8BizBxsjmIxr8AAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x2e53310>"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is qualitatively the result we wanted. Observing that the specificity decreases along with the sensitivity. Yet the result we would really like is to have the specificity decreasing faster than the sensitivity"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Another solution to modeling effect of motivation on performance"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I am presenting here an alternative to the previous model. This one is more \"reinforcement learning\" like. It is based on action values. There are two actions (lick, no-lick) for each state (go / no-go). It is hardwired that licking is an effective way to decrease thirst, the mouse is learning to associate the lick and a go stimulus. The motivation is modulating the value of licking independently of the state. A thirsty animal will lick more and a satiated animal will lick less. In the RL framework it means that the licking action has more value and the no-licking action has less value. In this case the Q init already specify that the mouse should lick when there is water and not otherwise."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def motivation_effect(q, motivation):\n",
      "    \"\"\"Modify the Q-values depending on the motivation of the agent\"\"\"\n",
      "    q_motiv = np.zeros(q.shape)\n",
      "    for action in range(2):\n",
      "        for state in range(2):\n",
      "            if action == 1:\n",
      "                q_motiv[state, action] = q[state, action] + 3*motivation\n",
      "            else: \n",
      "                q_motiv[state, action] = q[state, action] - 3*motivation\n",
      "    return q_motiv\n",
      "\n",
      "def testbed(states, q_init = np.zeros((2,2)), learning=True, motivation=True, thirst=1):\n",
      "    \"\"\"\n",
      "    Launch a testbed determined by the obs array for an agent with one or two fix or plastic learning rates\n",
      "\n",
      "    PARAMETERS\n",
      "    -----\n",
      "    states: array\n",
      "        observation correponding to states\n",
      "\n",
      "    RETURNS\n",
      "    -------\n",
      "    rec_choice: array\n",
      "         recording the choice of the agent for each episode and each iteration\n",
      "    rec_q: array\n",
      "         recording the internal q-values of the agent\n",
      "    rec_reward: array\n",
      "         recording the learning rates\n",
      "    \"\"\"\n",
      "    n_trials = len(states)\n",
      "    expected_actions = states\n",
      "\n",
      "    rec_q = np.zeros((n_trials, 2, 2), np.float)\n",
      "    rec_action = np.zeros(n_trials, np.int)\n",
      "    rec_reward = np.zeros(n_trials, np.int)\n",
      "\n",
      "    q_est = q_init\n",
      "    for i in range(n_trials):\n",
      "        #Modify the Q estimates given the motivation\n",
      "        if motivation:\n",
      "            q_est = motivation_effect(q_init, thirst)\n",
      "        #Choose given the Q estimates and the state\n",
      "        action = softmax(q_est[states[i]])\n",
      "        #Record the choice\n",
      "        rec_action[i] = action\n",
      "        if states[i] == 1:\n",
      "            if action == 1:\n",
      "                reward = 1\n",
      "            else:\n",
      "                reward = 0\n",
      "        else:\n",
      "            reward = 0\n",
      "        rec_reward[i] = reward\n",
      "        #Update the q_values gove the state, action and reward\n",
      "        if learning:\n",
      "            q_est[states[i], action] = set_qnext(q_est[states[i], action], reward)\n",
      "\n",
      "        #Record Q estimate\n",
      "        rec_q[i] = q_est\n",
      "        thirst -= 0.01\n",
      "        #import pdb; pdb.set_trace()\n",
      "\n",
      "    return rec_q, rec_action, rec_reward\n",
      "\n",
      "def motiv_expe(itsit=1, motivation=True):\n",
      "    \"\"\"An experiment where the motivation matters\n",
      "    #Define the intensity of licking\n",
      "    itsit = 1\"\"\"\n",
      "    #For action 0 (no-go) then there is no-lick (0)\n",
      "    #And for action\n",
      "    q_init = np.array([[itsit,-itsit],\n",
      "                      [-itsit,itsit]])\n",
      "    #Initiate the motivation\n",
      "    thirst = itsit\n",
      "    states = stimulus(200, 0.5)\n",
      "    rec_q, rec_action, rec_reward = testbed(states, q_init, motivation=motivation)\n",
      "    return states, rec_action\n",
      "\n",
      "\n",
      "def spe_sen(target, actual):\n",
      "    \"\"\"Compute the (specificity,sensitivity) couple given a target and actual outcome\n",
      "\n",
      "    parameters\n",
      "    ----------\n",
      "    target : Boolean array\n",
      "        actions taken\n",
      "    actual : Boolean array\n",
      "        actions expected\n",
      "\n",
      "    returns\n",
      "    -------\n",
      "    spe : a float between 0 and 1\n",
      "    sen : a float between 0 and 1\n",
      "    \"\"\"\n",
      "    #Use the binary of the vector to see the difference between actual and target\n",
      "    tp = np.array(target)*2 - actual\n",
      "    TN = len(np.repeat(tp,tp==0))\n",
      "    FN = len(np.repeat(tp,tp==2))\n",
      "    TP = len(np.repeat(tp,tp==1))\n",
      "    FP = len(np.repeat(tp,tp==-1))\n",
      "\n",
      "    spe = float(TN)/(TN+FP)\n",
      "    sen = float(TP)/(TP+FN)\n",
      "\n",
      "    return spe, sen\n",
      "\n",
      "repetition = 100\n",
      "n_c = 3\n",
      "spe = np.zeros((repetition, n_c))\n",
      "sen = np.zeros((repetition, n_c))\n",
      "for i in range(repetition):\n",
      "    G, L = motiv_expe(1, False)\n",
      "    spe[i], sen[i] = analysis(L, G, n_c)\n",
      "\n",
      "plot(1 - np.mean(spe, axis=0), color='r')\n",
      "plot(np.mean(sen, axis=0), color='g')\n",
      "plt.xlabel(\"Chunk#\")\n",
      "plt.ylabel(\"Probability\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "<matplotlib.text.Text at 0x4ff8410>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngsAAAABOEBgAAMAJAgMAADj5/4iVYlYyTmT4AAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x4ddbd10>"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There is no learning here, this is a pure effect of motivation showing that it changes the performance along time during a single session. Another way to see this effect is to look at the trajectory on the ROC curve."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run lib.py\n",
      "repetition = 10\n",
      "n_c = 3\n",
      "spe = np.zeros((repetition, n_c))\n",
      "sen = np.zeros((repetition, n_c))\n",
      "for i in range(repetition):\n",
      "    G, L = motiv_exp(1, motivation=False)\n",
      "    spe[i], sen[i] = analysis(L, G, n_c)\n",
      "\n",
      "plot(1 - np.mean(spe, axis=0), color='r')\n",
      "plot(np.mean(sen, axis=0), color='g')\n",
      "plt.xlabel(\"Chunk#\")\n",
      "plt.ylabel(\"Probability\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "testbed() got an unexpected keyword argument 'motivation'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-24-149a2a593036>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepetition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_c\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepetition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmotiv_exp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmotivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mspe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msen\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_c\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/rcaze/Documents/Articles/15_02BeCaSc/Scripts/lib.py\u001b[0m in \u001b[0;36mmotiv_exp\u001b[1;34m(itsit, motivation)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstimulus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m     \u001b[0mrec_q\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrec_action\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrec_reward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestbed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmotivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrec_action\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mTypeError\u001b[0m: testbed() got an unexpected keyword argument 'motivation'"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "spe"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "array([[ 0.1       ,  0.74285714,  0.96296296],\n",
        "       [ 0.23684211,  0.91176471,  0.96875   ],\n",
        "       [ 0.2       ,  0.87096774,  1.        ],\n",
        "       [ 0.18918919,  0.86111111,  0.97058824],\n",
        "       [ 0.24137931,  0.85714286,  1.        ],\n",
        "       [ 0.26666667,  0.9       ,  1.        ],\n",
        "       [ 0.17142857,  0.78787879,  1.        ],\n",
        "       [ 0.17777778,  0.90322581,  1.        ],\n",
        "       [ 0.125     ,  0.75675676,  1.        ],\n",
        "       [ 0.125     ,  0.87878788,  1.        ]])"
       ]
      }
     ],
     "prompt_number": 18
    }
   ],
   "metadata": {}
  }
 ]
}